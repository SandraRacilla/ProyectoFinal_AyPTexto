{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8xS3jEpo5Bf"
   },
   "source": [
    "# **Minería de tópicos**\n",
    " Basado en el artículo *Python for NLP: Topic Modeling* por Usman Malik https://stackabuse.com/python-for-nlp-topic-modeling/\n",
    "## Importación de Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyAQM-C1IT0r"
   },
   "source": [
    "# Sección nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9CBcQMnop13k"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvO65IluvF35"
   },
   "source": [
    "\n",
    "## Función Minería de Tópicos Non-Negative Matrix Factorization\n",
    "\n",
    "\n",
    "Antes aplicar el algoritmo de NMF es necesario obtener el vocabulario del archivo\n",
    "\n",
    "NMF hace uso de TFIDF\n",
    "\n",
    "max_df=0.80 -> Palabras que aparezcan al menos en 80% del documento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qBf5BFb9v4aS"
   },
   "outputs": [],
   "source": [
    "def txt_NMF(reviews_datasets_NMF):\n",
    "    \"\"\"\n",
    "    Antes aplicar el algoritmo de NMF es necesario obtener el vocabulario del archivo\n",
    "    NMF hace uso de TFIDF\n",
    "    max_df=0.80 -> Palabras que aparezcan al menos en 80% del documento\n",
    "    min_df=2 -> Palabras que aparezcan al menos en 2 documentos\n",
    "    \"\"\"\n",
    "    my_stop_words=text.ENGLISH_STOP_WORDS.union([\"https\"],[\"nhttps\"],[\"d4leu57x7h\"])\n",
    "    tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words=my_stop_words)\n",
    "    ##Matriz generada con TFIDF\n",
    "    doc_term_matrix = tfidf_vect.fit_transform(reviews_datasets_NMF['data__text'].values.astype('U'))\n",
    "    \"\"\"\n",
    "    Uso de NMF para crear temas junto con la distribución de probabilidad para cada palabra del vocabulario\n",
    "    n_components:5 -> Numero de categorias o temas que en las que queremos\n",
    "                        que se divida nuestro texto\n",
    "    random_state:42 -> seed \n",
    "    Creamos una matriz de probabilidad con las probabilidades de todas las palabras en el vocabulario\n",
    "    \"\"\"\n",
    "    nmf = NMF(n_components=5, random_state=42)\n",
    "    nmf.fit(doc_term_matrix )\n",
    "\n",
    "  \n",
    "    \"\"\"\n",
    "    ###Palabras de nuestro vocabulario\n",
    "    for i in range(10):\n",
    "        random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
    "        print(tfidf_vect.get_feature_names()[random_id])\n",
    "    \"\"\"\n",
    "    ##Para encontrar el primer topic se usa \"components_\" con atributo 0\n",
    "    first_topic = nmf.components_[0]\n",
    "    ##first_topic contiene la probabilidad de 3716 palabras para el topic 1\n",
    "    ##Ordenamos los índices de acuerdo a los valores de las probabilidades\n",
    "    ##Regresa indíces de 10 palabras con las probabilidades más altas\n",
    "    top_topic_words = first_topic.argsort()[-10:]\n",
    "    \"\"\"\n",
    "    Pasamos índices al vector para observar las palabras\n",
    "    \n",
    "    for i in top_topic_words:\n",
    "        print(tfidf_vect.get_feature_names()[i])\n",
    "    \"\"\"\n",
    "    fic = open(\"topics_NMF.txt\", \"w\")\n",
    "    print('\\t\\t\\t\\tTemas NMF', file=fic)\n",
    "    for i,topic in enumerate(nmf.components_):\n",
    "        print(f'NMF Top 10 words for topic #{i}:', file=fic)\n",
    "        print(f'NMF Top 10 words for topic #{i}:')\n",
    "        print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]], file=fic)\n",
    "        print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "        print('\\n\\n', file=fic)\n",
    "        print('\\n\\n')\n",
    "    fic.close()\n",
    "\n",
    "    topic_values = nmf.transform(doc_term_matrix)\n",
    "    reviews_datasets_NMF['Topic'] = topic_values.argmax(axis=1)\n",
    "    print(reviews_datasets_NMF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJiz76FzGAO8"
   },
   "source": [
    "## Función Minería de Tópicos Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XauTlh_6GS4H"
   },
   "outputs": [],
   "source": [
    "def txt_LDA(reviews_datasets_LDA):\n",
    "    \"\"\"\n",
    "    Antes aplicar el algoritmo de LDA es necesario obtener el vocabulario\n",
    "    del archivo\n",
    "    max_df=0.80 -> Palabras que aparezcan al menos en 80% del documento\n",
    "    min_df=2 -> Palabras que aparezcan al menos en 2 documentos\n",
    "    \"\"\"\n",
    "    my_stop_words=text.ENGLISH_STOP_WORDS.union([\"https\"],[\"nhttps\"],[\"d4leu57x7h\"])\n",
    "    count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words=my_stop_words)\n",
    "    doc_term_matrix = count_vect.fit_transform(reviews_datasets_LDA['data__text'].values.astype('U'))\n",
    "\n",
    "    \"\"\"\n",
    "    Uso de LDA para crear temas junto con la distribución de probabilidad \n",
    "    para cada palabra del vocabulario\n",
    "    n_components:5 -> Numero de categorias o temas que en las que queremos\n",
    "                        que se divida nuestro texto\n",
    "    random_state:42 -> seed \n",
    "    \"\"\"\n",
    "    LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "    LDA.fit(doc_term_matrix)\n",
    "    \"\"\"\n",
    "    for i in range(10):\n",
    "        random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "        print(count_vect.get_feature_names()[random_id])\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Encontramos 10 palabras con la probabilidad más alta para los temas\n",
    "    first_topic contiene las probabilidades de 3716 palabras para el tema 1\n",
    "    argsort() Ordenar índices de acuerdo a los valores de probabilidades\n",
    "    [-10:] Toma los últimos 10 valores, es decir los que tienen mayor valor  \n",
    "    \"\"\"\n",
    "    first_topic = LDA.components_[0]\n",
    "    #print(len(first_topic))\n",
    "    top_topic_words = first_topic.argsort()[-10:]\n",
    "    #print(top_topic_words)\n",
    "\n",
    "    \"\"\"\n",
    "    Obtenemos palabras relacionadas con los índices anteriores\n",
    "    \n",
    "    for i in top_topic_words:\n",
    "        print(count_vect.get_feature_names()[i])\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Impresion de 10 palabras con mayor probabilidad de cada uno de los 5 temas \n",
    "    \"\"\"\n",
    "    fic = open(\"topics_LDA.txt\", \"w\")\n",
    "    print('\\t\\t\\t\\tTemas LDA', file=fic)\n",
    "    for i,topic in enumerate(LDA.components_):\n",
    "        print(f'LDA Top 10 words for topic #{i}:', file=fic)\n",
    "        print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]], file=fic)\n",
    "        print('\\n\\n', file=fic)\n",
    "        print(f'LDA Top 10 words for topic #{i}:')\n",
    "        print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "        print('\\n\\n')\n",
    "    fic.close()\n",
    "\n",
    "    \"\"\"\n",
    "    Agregamos una columna al archivo donde agreguemos el tema al que pertenece\n",
    "    \"\"\"\n",
    "    topic_values = LDA.transform(doc_term_matrix)\n",
    "    topic_values.shape\n",
    "    reviews_datasets_LDA['Topic'] = topic_values.argmax(axis=1)\n",
    "    print(reviews_datasets_LDA.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suV1QlQ5Gezd"
   },
   "source": [
    "Importación de Datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "2keoydmoGwl6",
    "outputId": "7405f904-4a32-4f77-8c5f-110e2a228b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Top 10 words for topic #0:\n",
      "['death', 'amp', 'hill', 'died', 'building', 'just', 'trump', 'officer', 'people', 'police']\n",
      "\n",
      "\n",
      "\n",
      "LDA Top 10 words for topic #1:\n",
      "['people', 'peacefully', 'amp', 'police', '2021', 'heard', 'building', 'president', 'know', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "LDA Top 10 words for topic #2:\n",
      "['building', 'violence', 'attack', 'did', 'amp', 'just', 'riot', 'police', 'people', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "LDA Top 10 words for topic #3:\n",
      "['building', 'president', 'yes', 'storming', 'mob', 'amp', 'job', 'inside', 'trump', 'attack']\n",
      "\n",
      "\n",
      "\n",
      "LDA Top 10 words for topic #4:\n",
      "['did', 'help', 'insurrection', 'just', 'attack', 'right', 'stormed', 'people', 'like', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "              data__id data__lang  \\\n",
      "0  1347495838839238657         en   \n",
      "1  1347495838688440320         en   \n",
      "2  1347495838063284230         en   \n",
      "3  1347495834833747969         en   \n",
      "4  1347495834439606272         en   \n",
      "\n",
      "                                          data__text  Topic  \n",
      "0  @PapaGlider @Jessica26307123 @MontyBoa99 @real...      2  \n",
      "1  US Capitol: Police confirms death of officer i...      2  \n",
      "2  @HookRocky @NBCNews @NBCNewsTHINK At least we ...      0  \n",
      "3  Mike Pompeo Says Capitol Riot Proves U.S. Isn'...      1  \n",
      "4  US Capitol Attack: President Trump Can’t Handl...      4  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NMF Top 10 words for topic #0:\n",
      "['donald', '2021', 'january', 'make', 'heard', 'peacefully', 'soon', 'voices', 'marching', 'patriotically']\n",
      "\n",
      "\n",
      "\n",
      "NMF Top 10 words for topic #1:\n",
      "['like', 'mob', 'did', 'violence', 'just', 'stormed', 'supporters', 'people', 'amp', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "NMF Top 10 words for topic #2:\n",
      "['mo', 'lead', 'paul', 'organizer', 'gosar', 'andy', 'biggs', 'job', 'inside', 'attack']\n",
      "\n",
      "\n",
      "\n",
      "NMF Top 10 words for topic #3:\n",
      "['investigation', 'realdonaldtrump', 'murder', 'pro', 'confirms', 'injured', 'riot', 'death', 'officer', 'police']\n",
      "\n",
      "\n",
      "\n",
      "NMF Top 10 words for topic #4:\n",
      "['know', 'coup', 'taking', 'act', 'coming', 'committing', 'security', 'skirting', 'people', 'weapons']\n",
      "\n",
      "\n",
      "\n",
      "              data__id data__lang  \\\n",
      "0  1347495838839238657         en   \n",
      "1  1347495838688440320         en   \n",
      "2  1347495838063284230         en   \n",
      "3  1347495834833747969         en   \n",
      "4  1347495834439606272         en   \n",
      "\n",
      "                                          data__text  Topic  \n",
      "0  @PapaGlider @Jessica26307123 @MontyBoa99 @real...      1  \n",
      "1  US Capitol: Police confirms death of officer i...      3  \n",
      "2  @HookRocky @NBCNews @NBCNewsTHINK At least we ...      1  \n",
      "3  Mike Pompeo Says Capitol Riot Proves U.S. Isn'...      1  \n",
      "4  US Capitol Attack: President Trump Can’t Handl...      1  \n"
     ]
    }
   ],
   "source": [
    "reviews_datasets = pd.read_csv(r'Tweets Recabados.csv',engine='python')\n",
    "reviews_datasets = reviews_datasets.head(2429)\n",
    "reviews_datasets.dropna()\n",
    "\n",
    "txt_LDA(reviews_datasets)\n",
    "print('\\n\\n\\n\\n')\n",
    "txt_NMF(reviews_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Minería de Tópicos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
